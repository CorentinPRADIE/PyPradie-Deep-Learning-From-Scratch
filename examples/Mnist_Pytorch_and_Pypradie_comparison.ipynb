{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "The goal of building **PyPradie** is not to replace PyTorch, but to gain a deeper understanding of the core concepts behind a deep learning library. These core concepts include:\n",
    "\n",
    "- **Autograd**: Automatic differentiation and backpropagation.\n",
    "- **Optimization**: Gradient-based optimization methods like SGD.\n",
    "- **Neural Network Layers**: Basic building blocks such as linear layers and activation functions.\n",
    "- **Tensors**: Efficient multidimensional arrays with support for mathematical operations.\n",
    "\n",
    "Although PyPradie is not intended to replace PyTorch, it replicates the PyTorch API, allowing easy switching between the two libraries. This makes it interesting to compare their performance side by side to see if PyPradie can come close to PyTorch in terms of efficiency and accuracy.\n",
    "\n",
    "In this notebook, we will perform a comparison between PyTorch and PyPradie on the **MNIST digit classification task** to see how PyPradie measures up.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Loading the Library\n",
    "\n",
    "The `get_framework` function dynamically loads either PyTorch or PyPradie based on the library name provided. This allows us to easily switch between the two frameworks in the same code.\n",
    "\n",
    "- **PyTorch** is a well-known deep learning framework used widely in research and production.\n",
    "- **PyPradie** is a custom library built to mimic PyTorch's structure and functionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import psutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown\n",
    "np.random.seed(42)\n",
    "\n",
    "# Function to dynamically load the correct library (PyTorch or PyPradie)\n",
    "def get_framework(library_name):\n",
    "    if library_name == \"PyPradie\":\n",
    "        import pypradie as dl_framework\n",
    "    else:\n",
    "        import torch as dl_framework\n",
    "    return dl_framework\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Loading and Preprocessing the Data\n",
    "\n",
    "The `load_data` function reads the MNIST dataset and prepares it for training. We normalize the pixel values and convert the features and labels into tensors. \n",
    "\n",
    "This function also uses `DataLoader` to create iterable batches for training and testing, which helps in efficiently handling large datasets.\n",
    "\n",
    "- **Train Data**: 60,000 images and corresponding labels.\n",
    "- **Test Data**: 10,000 images and corresponding labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess the MNIST data\n",
    "def load_data(dl_framework, batch_size=64):\n",
    "    train_df = pd.read_csv('../datasets/mnist/mnist_train.csv')\n",
    "    test_df = pd.read_csv('../datasets/mnist/mnist_test.csv')\n",
    "    \n",
    "    # Extract labels and normalize features\n",
    "    train_labels = train_df['label'].values\n",
    "    train_features = train_df.drop('label', axis=1).values / 255.0  # Normalize pixel values\n",
    "    test_labels = test_df['label'].values\n",
    "    test_features = test_df.drop('label', axis=1).values / 255.0\n",
    "    \n",
    "    # Convert to framework-specific tensors\n",
    "    tensor = dl_framework.tensor\n",
    "    train_features_tensor = tensor(train_features, dtype=dl_framework.float32)\n",
    "    train_labels_tensor = tensor(train_labels, dtype=dl_framework.long)\n",
    "    test_features_tensor = tensor(test_features, dtype=dl_framework.float32)\n",
    "    test_labels_tensor = tensor(test_labels, dtype=dl_framework.long)\n",
    "    \n",
    "    # Use DataLoader for batching and shuffling\n",
    "    DataLoader = dl_framework.utils.data.DataLoader\n",
    "    TensorDataset = dl_framework.utils.data.TensorDataset\n",
    "    train_dataset = TensorDataset(train_features_tensor, train_labels_tensor)\n",
    "    test_dataset = TensorDataset(test_features_tensor, test_labels_tensor)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return train_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Defining the Model\n",
    "\n",
    "The `build_model` function defines a simple fully connected neural network (Multi-Layer Perceptron) with the following architecture:\n",
    "- Input layer: 784 input units (28 x 28 pixels).\n",
    "- Two hidden layers with 128 and 64 units, each followed by ReLU activation.\n",
    "- Output layer: 10 units for the 10 possible digit classes (0-9).\n",
    "\n",
    "The loss function is **CrossEntropyLoss**, and the optimizer is **Stochastic Gradient Descent (SGD)**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the model, loss function, and optimizer\n",
    "def build_model(dl_framework):\n",
    "    nn = dl_framework.nn\n",
    "    model = nn.Sequential(\n",
    "        nn.Linear(28 * 28, 128),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(128, 64),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(64, 10),\n",
    "    )\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = dl_framework.optim.SGD(model.parameters(), lr=0.01)\n",
    "    return model, criterion, optimizer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Tracking Memory Usage\n",
    "\n",
    "We track the memory usage during training using the `psutil` library. The `memory_usage_psutil` function returns the resident memory size (RSS) in megabytes, allowing us to measure the memory consumption of each framework.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memory usage tracking\n",
    "def memory_usage_psutil():\n",
    "    \"\"\"Return the memory usage in MB.\"\"\"\n",
    "    process = psutil.Process()\n",
    "    mem_info = process.memory_info()\n",
    "    return mem_info.rss / 1024 ** 2  # Memory in MB\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Training the Model\n",
    "\n",
    "The `train_model` function trains the model over multiple epochs, tracking important metrics like training accuracy, loss, epoch time, and memory usage.\n",
    "\n",
    "- For each epoch, we:\n",
    "  1. Forward pass: Compute the output of the model.\n",
    "  2. Backpropagation: Calculate the gradients.\n",
    "  3. Optimization: Update the model's parameters using the gradients.\n",
    "\n",
    "We also measure how much memory the framework consumes during each epoch and record it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function with memory usage tracking\n",
    "def train_model(dl_framework, model, criterion, optimizer, train_loader, epochs=5):\n",
    "    tracking_data = {'train_accuracy': [], 'train_loss': [], 'epoch_time': [], 'memory_usage': []}\n",
    "    tensor = dl_framework.tensor\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_train = 0\n",
    "        total_train = 0\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Capture memory before training\n",
    "        memory_before = memory_usage_psutil()\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            images = images.view(images.size(0), -1)  # Flatten images\n",
    "            optimizer.zero_grad()  # Zero gradients\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()  # Backpropagation\n",
    "            optimizer.step()  # Optimization\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            predicted = dl_framework.argmax(outputs.detach(), dim=1)\n",
    "            total_train += labels.size(0)\n",
    "            correct_train += (predicted == labels).sum().item()\n",
    "        \n",
    "        # Capture memory after training\n",
    "        memory_after = memory_usage_psutil()\n",
    "        epoch_memory_usage = memory_after - memory_before  # Measure memory used during training\n",
    "        \n",
    "        epoch_time = time.time() - start_time\n",
    "        train_accuracy = 100 * correct_train / total_train\n",
    "        tracking_data['train_accuracy'].append(train_accuracy)\n",
    "        tracking_data['train_loss'].append(running_loss / len(train_loader))\n",
    "        tracking_data['epoch_time'].append(epoch_time)\n",
    "        tracking_data['memory_usage'].append(epoch_memory_usage)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss/len(train_loader):.6f}, Time: {epoch_time:.2f}s, Accuracy: {train_accuracy:.2f}%, Memory: {epoch_memory_usage:.2f} MB\")\n",
    "    \n",
    "    return tracking_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Testing the Model\n",
    "\n",
    "The `test_model` function evaluates the trained model on the test dataset. It calculates the test accuracy by comparing the predicted labels with the true labels and disables gradient calculation to improve performance during inference.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing function\n",
    "def test_model(dl_framework, model, test_loader):\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "    tensor = dl_framework.tensor\n",
    "    \n",
    "    with dl_framework.no_grad():  # Disable gradients for testing\n",
    "        for images, labels in test_loader:\n",
    "            images = images.view(images.size(0), -1)  # Flatten images\n",
    "            outputs = model(images)\n",
    "            predicted = dl_framework.argmax(outputs, dim=1)\n",
    "            total_test += labels.size(0)\n",
    "            correct_test += (predicted == labels).sum().item()\n",
    "    \n",
    "    test_accuracy = 100 * correct_test / total_test\n",
    "    return test_accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Displaying Results in a Table\n",
    "\n",
    "The `display_results_as_table` function creates a markdown table that compares PyTorch and PyPradie across several key metrics:\n",
    "- **Train Accuracy**\n",
    "- **Test Accuracy**\n",
    "- **Total Training Time**\n",
    "- **Memory Usage**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create and display the result as a markdown table\n",
    "def display_results_as_table(pytorch_data, pypradie_data, pytorch_test_acc, pypradie_test_acc):\n",
    "    # Calculate average memory usage\n",
    "    pytorch_memory = sum(pytorch_data['memory_usage']) / len(pytorch_data['memory_usage'])\n",
    "    pypradie_memory = sum(pypradie_data['memory_usage']) / len(pypradie_data['memory_usage'])\n",
    "    \n",
    "    # Create a markdown table string with results\n",
    "    table = f\"\"\"\n",
    "| Metric            | PyTorch Value   | PyPradie Value   |\n",
    "|-------------------|-----------------|------------------|\n",
    "| Train Accuracy (%) | {pytorch_data['train_accuracy'][-1]:.2f} | {pypradie_data['train_accuracy'][-1]:.2f} |\n",
    "| Test Accuracy (%)  | {pytorch_test_acc:.2f} | {pypradie_test_acc:.2f} |\n",
    "| Total Training Time (s)  | {sum(pytorch_data['epoch_time']):.2f} | {sum(pypradie_data['epoch_time']):.2f} |\n",
    "| Memory Usage (MB)  | {pytorch_memory:.2f} | {pypradie_memory:.2f} |\n",
    "\"\"\"\n",
    "    # Display the markdown table in a Jupyter Notebook\n",
    "    display(Markdown(table))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training PyTorch...\n",
      "Epoch 1/5, Loss: 1.931128, Time: 1.74s, Accuracy: 48.90%, Memory: 5.86 MB\n",
      "Epoch 2/5, Loss: 0.697695, Time: 1.75s, Accuracy: 82.68%, Memory: 0.00 MB\n",
      "Epoch 3/5, Loss: 0.440056, Time: 1.78s, Accuracy: 87.92%, Memory: 0.00 MB\n",
      "Epoch 4/5, Loss: 0.374822, Time: 1.69s, Accuracy: 89.47%, Memory: 0.00 MB\n",
      "Epoch 5/5, Loss: 0.342004, Time: 1.62s, Accuracy: 90.32%, Memory: 0.00 MB\n",
      "\n",
      "Testing PyTorch...\n",
      "Test Accuracy for PyTorch: 90.78%\n",
      "\n",
      "Training PyPradie...\n",
      "Epoch 1/5, Loss: 0.963588, Time: 1.20s, Accuracy: 75.76%, Memory: 4.16 MB\n",
      "Epoch 2/5, Loss: 0.409649, Time: 1.12s, Accuracy: 88.61%, Memory: 0.09 MB\n",
      "Epoch 3/5, Loss: 0.338920, Time: 1.03s, Accuracy: 90.32%, Memory: 0.00 MB\n",
      "Epoch 4/5, Loss: 0.303822, Time: 1.03s, Accuracy: 91.36%, Memory: 0.00 MB\n",
      "Epoch 5/5, Loss: 0.278770, Time: 1.02s, Accuracy: 92.01%, Memory: 0.00 MB\n",
      "\n",
      "Testing PyPradie...\n",
      "Test Accuracy for PyPradie: 92.67%\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "| Metric            | PyTorch Value   | PyPradie Value   |\n",
       "|-------------------|-----------------|------------------|\n",
       "| Train Accuracy (%) | 90.32 | 92.01 |\n",
       "| Test Accuracy (%)  | 90.78 | 92.67 |\n",
       "| Total Training Time (s)  | 8.58 | 5.40 |\n",
       "| Memory Usage (MB)  | 1.17 | 0.85 |\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Main function to run the experiment and compare PyTorch and PyPradie\n",
    "def compare_libraries():\n",
    "    libraries = ['PyTorch', 'PyPradie']\n",
    "    comparison_data = {}\n",
    "\n",
    "    for library in libraries:\n",
    "        dl_framework = get_framework(library)\n",
    "        \n",
    "        # Load data and build the model\n",
    "        train_loader, test_loader = load_data(dl_framework)\n",
    "        model, criterion, optimizer = build_model(dl_framework)\n",
    "        \n",
    "        # Train the model\n",
    "        print(f\"\\nTraining {library}...\")\n",
    "        train_data = train_model(dl_framework, model, criterion, optimizer, train_loader)\n",
    "        \n",
    "        # Test the model\n",
    "        print(f\"\\nTesting {library}...\")\n",
    "        test_accuracy = test_model(dl_framework, model, test_loader)\n",
    "        print(f\"Test Accuracy for {library}: {test_accuracy:.2f}%\")\n",
    "        \n",
    "        # Store data for comparison\n",
    "        comparison_data[library] = {'train_data': train_data, 'test_accuracy': test_accuracy}\n",
    "    \n",
    "    # Extract results for both libraries\n",
    "    pytorch_data = comparison_data['PyTorch']['train_data']\n",
    "    pypradie_data = comparison_data['PyPradie']['train_data']\n",
    "    pytorch_test_acc = comparison_data['PyTorch']['test_accuracy']\n",
    "    pypradie_test_acc = comparison_data['PyPradie']['test_accuracy']\n",
    "    \n",
    "    # Display results as a markdown table\n",
    "    display_results_as_table(pytorch_data, pypradie_data, pytorch_test_acc, pypradie_test_acc)\n",
    "\n",
    "# Run the comparison\n",
    "compare_libraries()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Results and Interpretation\n",
    "\n",
    "The results for both frameworks are presented below:\n",
    "\n",
    "| Metric            | PyTorch Value   | PyPradie Value   |\n",
    "|-------------------|-----------------|------------------|\n",
    "| Train Accuracy (%) | 90.86           | 92.97            |\n",
    "| Test Accuracy (%)  | 91.49           | 93.36            |\n",
    "| Total Training Time (s)  | 11.44           | 6.43             |\n",
    "| Memory Usage (MB)  | 1.41            | 0.86             |\n",
    "\n",
    "### Interpretation:\n",
    "\n",
    "- **Accuracy**: PyPradie slightly outperforms PyTorch in both training accuracy (92.97% vs. 90.86%) and test accuracy (93.36% vs. 91.49%). This demonstrates that PyPradie is capable of generalizing well on the MNIST task, despite being a custom framework for learning purposes.\n",
    "- **Training Time**: PyPradie completes training in nearly half the time of PyTorch (6.43s vs. 11.44s), showing a significant performance advantage for this specific task.\n",
    "- **Memory Usage**: PyPradie uses less memory (0.86 MB) than PyTorch (1.41 MB), highlighting its potential for efficiency.\n",
    "\n",
    "While PyPradie is not designed to replace PyTorch, comparing the two helps us assess whether PyPradie’s performance is in the same ballpark. The results show that PyPradie is quite efficient for this task, and replicating the PyTorch API allows easy switching between the two libraries.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
